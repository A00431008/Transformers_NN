{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCDA5511 Assignment 3 : Transformers\n",
    "\n",
    "Submitted By:\n",
    "- Louise Fear\n",
    "- Muhammad Abdul Thoufiq\n",
    "- Sudeep Raj Badal\n",
    "- Sukanta Dey Amit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_gender</th>\n",
       "      <th>person_education</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_exp</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>previous_loan_defaults_on_file</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Master</td>\n",
       "      <td>71948.0</td>\n",
       "      <td>0</td>\n",
       "      <td>RENT</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>16.02</td>\n",
       "      <td>0.49</td>\n",
       "      <td>3.0</td>\n",
       "      <td>561</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>female</td>\n",
       "      <td>High School</td>\n",
       "      <td>12282.0</td>\n",
       "      <td>0</td>\n",
       "      <td>OWN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>11.14</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>504</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>female</td>\n",
       "      <td>High School</td>\n",
       "      <td>12438.0</td>\n",
       "      <td>3</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>12.87</td>\n",
       "      <td>0.44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>635</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>79753.0</td>\n",
       "      <td>0</td>\n",
       "      <td>RENT</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>15.23</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2.0</td>\n",
       "      <td>675</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Master</td>\n",
       "      <td>66135.0</td>\n",
       "      <td>1</td>\n",
       "      <td>RENT</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>14.27</td>\n",
       "      <td>0.53</td>\n",
       "      <td>4.0</td>\n",
       "      <td>586</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_age person_gender person_education  person_income  person_emp_exp  \\\n",
       "0        22.0        female           Master        71948.0               0   \n",
       "1        21.0        female      High School        12282.0               0   \n",
       "2        25.0        female      High School        12438.0               3   \n",
       "3        23.0        female         Bachelor        79753.0               0   \n",
       "4        24.0          male           Master        66135.0               1   \n",
       "\n",
       "  person_home_ownership  loan_amnt loan_intent  loan_int_rate  \\\n",
       "0                  RENT    35000.0    PERSONAL          16.02   \n",
       "1                   OWN     1000.0   EDUCATION          11.14   \n",
       "2              MORTGAGE     5500.0     MEDICAL          12.87   \n",
       "3                  RENT    35000.0     MEDICAL          15.23   \n",
       "4                  RENT    35000.0     MEDICAL          14.27   \n",
       "\n",
       "   loan_percent_income  cb_person_cred_hist_length  credit_score  \\\n",
       "0                 0.49                         3.0           561   \n",
       "1                 0.08                         2.0           504   \n",
       "2                 0.44                         3.0           635   \n",
       "3                 0.44                         2.0           675   \n",
       "4                 0.53                         4.0           586   \n",
       "\n",
       "  previous_loan_defaults_on_file  loan_status  \n",
       "0                             No            1  \n",
       "1                            Yes            0  \n",
       "2                             No            1  \n",
       "3                             No            1  \n",
       "4                             No            1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"loan_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Prep\n",
    "\n",
    "Handle missing values and encode categorical features and normalize the numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values (impute or drop)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "categorical_cols = [\"person_gender\", \"person_education\", \"person_home_ownership\", \"loan_intent\", \"previous_loan_defaults_on_file\"]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Select features and target\n",
    "X = df.drop(columns=[\"loan_status\"])\n",
    "y = df[\"loan_status\"]\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Data\n",
    "\n",
    "Split into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8901\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "log_reg_accuracy = accuracy_score(y_test, y_pred_log_reg)\n",
    "print(f\"Logistic Regression Accuracy: {log_reg_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, learning_rate=0.01, epochs=1000):\n",
    "        # Initialization of NN\n",
    "        self.input_size = input_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = np.random.randn(input_size, 1) * 0.01    # Generate random weights\n",
    "        self.bias = np.zeros((1,))\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        # Sigmoid Activation Function\n",
    "        return 1/(1 + np.exp(-z))\n",
    "    \n",
    "    def sigmoid_derivative(self, z):\n",
    "        # Derivative of Sigmoid Activation Function\n",
    "        return self.sigmoid(z) * (1 - self.sigmoid(z))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        #Forward Propagation to compute Predictions\n",
    "        z = np.dot(X, self.weights) + self.bias\n",
    "        return self.sigmoid(z)\n",
    "\n",
    "    def backward(self, X, y, y_pred):\n",
    "        # Backpropagation to compute gradients\n",
    "        n = X.shape[0]\n",
    "        dz = y_pred - y.values.reshape(-1,1)\n",
    "        dw = np.dot(X.T, dz) / n\n",
    "        db = np.sum(dz) / n\n",
    "        return dw, db\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        # Train the neural network using gradient descent\n",
    "        for epoch in range(self.epochs):\n",
    "            # Compute prediction from forward propagation\n",
    "            y_pred = self.forward(X)\n",
    "\n",
    "            # Get gradients from backpropagation\n",
    "            dw, db = self.backward(X, y, y_pred)\n",
    "\n",
    "            # Update weights and bias using gradients\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "            # Print loss every 100 epochs\n",
    "            # Loss calculated by Binary Cross \n",
    "            if epoch % 100 == 0:\n",
    "                loss = -np.mean(y.values.reshape(-1, 1) * np.log(y_pred + 1e-8) + (1 - y.values.reshape(-1, 1)) * np.log(1 - y_pred + 1e-8))\n",
    "                print(f\"Epoch: {epoch}, Loss: {loss:.4f}\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Predict using trained weights\n",
    "        return (self.forward(X) >= 0.5).astype(int) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model With 1000 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.6953\n",
      "Epoch: 100, Loss: 0.5547\n",
      "Epoch: 200, Loss: 0.4763\n",
      "Epoch: 300, Loss: 0.4277\n",
      "Epoch: 400, Loss: 0.3948\n",
      "Epoch: 500, Loss: 0.3711\n",
      "Epoch: 600, Loss: 0.3533\n",
      "Epoch: 700, Loss: 0.3394\n",
      "Epoch: 800, Loss: 0.3283\n",
      "Epoch: 900, Loss: 0.3191\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(input_size=X_train.shape[1], learning_rate=0.01, epochs=1000)\n",
    "nn.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Accuracy: 0.8843\n"
     ]
    }
   ],
   "source": [
    "y_pred_nn = nn.predict(X_test)\n",
    "nn_accuracy = accuracy_score(y_test, y_pred_nn)\n",
    "print(f\"Neural Network Accuracy: {nn_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model With 5,000 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.6982\n",
      "Epoch: 100, Loss: 0.5563\n",
      "Epoch: 200, Loss: 0.4773\n",
      "Epoch: 300, Loss: 0.4283\n",
      "Epoch: 400, Loss: 0.3953\n",
      "Epoch: 500, Loss: 0.3715\n",
      "Epoch: 600, Loss: 0.3536\n",
      "Epoch: 700, Loss: 0.3396\n",
      "Epoch: 800, Loss: 0.3285\n",
      "Epoch: 900, Loss: 0.3193\n",
      "Epoch: 1000, Loss: 0.3117\n",
      "Epoch: 1100, Loss: 0.3052\n",
      "Epoch: 1200, Loss: 0.2996\n",
      "Epoch: 1300, Loss: 0.2948\n",
      "Epoch: 1400, Loss: 0.2906\n",
      "Epoch: 1500, Loss: 0.2869\n",
      "Epoch: 1600, Loss: 0.2836\n",
      "Epoch: 1700, Loss: 0.2807\n",
      "Epoch: 1800, Loss: 0.2780\n",
      "Epoch: 1900, Loss: 0.2757\n",
      "Epoch: 2000, Loss: 0.2735\n",
      "Epoch: 2100, Loss: 0.2715\n",
      "Epoch: 2200, Loss: 0.2697\n",
      "Epoch: 2300, Loss: 0.2680\n",
      "Epoch: 2400, Loss: 0.2665\n",
      "Epoch: 2500, Loss: 0.2650\n",
      "Epoch: 2600, Loss: 0.2637\n",
      "Epoch: 2700, Loss: 0.2625\n",
      "Epoch: 2800, Loss: 0.2613\n",
      "Epoch: 2900, Loss: 0.2603\n",
      "Epoch: 3000, Loss: 0.2592\n",
      "Epoch: 3100, Loss: 0.2583\n",
      "Epoch: 3200, Loss: 0.2574\n",
      "Epoch: 3300, Loss: 0.2566\n",
      "Epoch: 3400, Loss: 0.2558\n",
      "Epoch: 3500, Loss: 0.2551\n",
      "Epoch: 3600, Loss: 0.2543\n",
      "Epoch: 3700, Loss: 0.2537\n",
      "Epoch: 3800, Loss: 0.2530\n",
      "Epoch: 3900, Loss: 0.2524\n",
      "Epoch: 4000, Loss: 0.2519\n",
      "Epoch: 4100, Loss: 0.2513\n",
      "Epoch: 4200, Loss: 0.2508\n",
      "Epoch: 4300, Loss: 0.2503\n",
      "Epoch: 4400, Loss: 0.2498\n",
      "Epoch: 4500, Loss: 0.2494\n",
      "Epoch: 4600, Loss: 0.2490\n",
      "Epoch: 4700, Loss: 0.2485\n",
      "Epoch: 4800, Loss: 0.2481\n",
      "Epoch: 4900, Loss: 0.2478\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(input_size=X_train.shape[1], learning_rate=0.01, epochs=5000)\n",
    "nn.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Accuracy: 0.8881\n"
     ]
    }
   ],
   "source": [
    "y_pred_nn = nn.predict(X_test)\n",
    "nn_accuracy = accuracy_score(y_test, y_pred_nn)\n",
    "print(f\"Neural Network Accuracy: {nn_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model With 10,000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.6937\n",
      "Epoch: 100, Loss: 0.5540\n",
      "Epoch: 200, Loss: 0.4760\n",
      "Epoch: 300, Loss: 0.4275\n",
      "Epoch: 400, Loss: 0.3947\n",
      "Epoch: 500, Loss: 0.3710\n",
      "Epoch: 600, Loss: 0.3532\n",
      "Epoch: 700, Loss: 0.3393\n",
      "Epoch: 800, Loss: 0.3282\n",
      "Epoch: 900, Loss: 0.3191\n",
      "Epoch: 1000, Loss: 0.3114\n",
      "Epoch: 1100, Loss: 0.3050\n",
      "Epoch: 1200, Loss: 0.2995\n",
      "Epoch: 1300, Loss: 0.2947\n",
      "Epoch: 1400, Loss: 0.2905\n",
      "Epoch: 1500, Loss: 0.2868\n",
      "Epoch: 1600, Loss: 0.2835\n",
      "Epoch: 1700, Loss: 0.2806\n",
      "Epoch: 1800, Loss: 0.2779\n",
      "Epoch: 1900, Loss: 0.2755\n",
      "Epoch: 2000, Loss: 0.2734\n",
      "Epoch: 2100, Loss: 0.2714\n",
      "Epoch: 2200, Loss: 0.2696\n",
      "Epoch: 2300, Loss: 0.2679\n",
      "Epoch: 2400, Loss: 0.2664\n",
      "Epoch: 2500, Loss: 0.2649\n",
      "Epoch: 2600, Loss: 0.2636\n",
      "Epoch: 2700, Loss: 0.2624\n",
      "Epoch: 2800, Loss: 0.2613\n",
      "Epoch: 2900, Loss: 0.2602\n",
      "Epoch: 3000, Loss: 0.2592\n",
      "Epoch: 3100, Loss: 0.2582\n",
      "Epoch: 3200, Loss: 0.2574\n",
      "Epoch: 3300, Loss: 0.2565\n",
      "Epoch: 3400, Loss: 0.2557\n",
      "Epoch: 3500, Loss: 0.2550\n",
      "Epoch: 3600, Loss: 0.2543\n",
      "Epoch: 3700, Loss: 0.2536\n",
      "Epoch: 3800, Loss: 0.2530\n",
      "Epoch: 3900, Loss: 0.2524\n",
      "Epoch: 4000, Loss: 0.2518\n",
      "Epoch: 4100, Loss: 0.2513\n",
      "Epoch: 4200, Loss: 0.2508\n",
      "Epoch: 4300, Loss: 0.2503\n",
      "Epoch: 4400, Loss: 0.2498\n",
      "Epoch: 4500, Loss: 0.2493\n",
      "Epoch: 4600, Loss: 0.2489\n",
      "Epoch: 4700, Loss: 0.2485\n",
      "Epoch: 4800, Loss: 0.2481\n",
      "Epoch: 4900, Loss: 0.2477\n",
      "Epoch: 5000, Loss: 0.2473\n",
      "Epoch: 5100, Loss: 0.2470\n",
      "Epoch: 5200, Loss: 0.2467\n",
      "Epoch: 5300, Loss: 0.2463\n",
      "Epoch: 5400, Loss: 0.2460\n",
      "Epoch: 5500, Loss: 0.2457\n",
      "Epoch: 5600, Loss: 0.2454\n",
      "Epoch: 5700, Loss: 0.2451\n",
      "Epoch: 5800, Loss: 0.2449\n",
      "Epoch: 5900, Loss: 0.2446\n",
      "Epoch: 6000, Loss: 0.2443\n",
      "Epoch: 6100, Loss: 0.2441\n",
      "Epoch: 6200, Loss: 0.2439\n",
      "Epoch: 6300, Loss: 0.2436\n",
      "Epoch: 6400, Loss: 0.2434\n",
      "Epoch: 6500, Loss: 0.2432\n",
      "Epoch: 6600, Loss: 0.2430\n",
      "Epoch: 6700, Loss: 0.2428\n",
      "Epoch: 6800, Loss: 0.2426\n",
      "Epoch: 6900, Loss: 0.2424\n",
      "Epoch: 7000, Loss: 0.2422\n",
      "Epoch: 7100, Loss: 0.2420\n",
      "Epoch: 7200, Loss: 0.2418\n",
      "Epoch: 7300, Loss: 0.2417\n",
      "Epoch: 7400, Loss: 0.2415\n",
      "Epoch: 7500, Loss: 0.2413\n",
      "Epoch: 7600, Loss: 0.2412\n",
      "Epoch: 7700, Loss: 0.2410\n",
      "Epoch: 7800, Loss: 0.2409\n",
      "Epoch: 7900, Loss: 0.2407\n",
      "Epoch: 8000, Loss: 0.2406\n",
      "Epoch: 8100, Loss: 0.2405\n",
      "Epoch: 8200, Loss: 0.2403\n",
      "Epoch: 8300, Loss: 0.2402\n",
      "Epoch: 8400, Loss: 0.2401\n",
      "Epoch: 8500, Loss: 0.2399\n",
      "Epoch: 8600, Loss: 0.2398\n",
      "Epoch: 8700, Loss: 0.2397\n",
      "Epoch: 8800, Loss: 0.2396\n",
      "Epoch: 8900, Loss: 0.2395\n",
      "Epoch: 9000, Loss: 0.2393\n",
      "Epoch: 9100, Loss: 0.2392\n",
      "Epoch: 9200, Loss: 0.2391\n",
      "Epoch: 9300, Loss: 0.2390\n",
      "Epoch: 9400, Loss: 0.2389\n",
      "Epoch: 9500, Loss: 0.2388\n",
      "Epoch: 9600, Loss: 0.2387\n",
      "Epoch: 9700, Loss: 0.2386\n",
      "Epoch: 9800, Loss: 0.2385\n",
      "Epoch: 9900, Loss: 0.2384\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(input_size=X_train.shape[1], learning_rate=0.01, epochs=10000)\n",
    "nn.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Accuracy: 0.8893\n"
     ]
    }
   ],
   "source": [
    "y_pred_nn = nn.predict(X_test)\n",
    "nn_accuracy = accuracy_score(y_test, y_pred_nn)\n",
    "print(f\"Neural Network Accuracy: {nn_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model with 15,000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.6955\n",
      "Epoch: 100, Loss: 0.5544\n",
      "Epoch: 200, Loss: 0.4759\n",
      "Epoch: 300, Loss: 0.4273\n",
      "Epoch: 400, Loss: 0.3944\n",
      "Epoch: 500, Loss: 0.3708\n",
      "Epoch: 600, Loss: 0.3530\n",
      "Epoch: 700, Loss: 0.3391\n",
      "Epoch: 800, Loss: 0.3280\n",
      "Epoch: 900, Loss: 0.3189\n",
      "Epoch: 1000, Loss: 0.3113\n",
      "Epoch: 1100, Loss: 0.3049\n",
      "Epoch: 1200, Loss: 0.2994\n",
      "Epoch: 1300, Loss: 0.2946\n",
      "Epoch: 1400, Loss: 0.2904\n",
      "Epoch: 1500, Loss: 0.2867\n",
      "Epoch: 1600, Loss: 0.2834\n",
      "Epoch: 1700, Loss: 0.2805\n",
      "Epoch: 1800, Loss: 0.2779\n",
      "Epoch: 1900, Loss: 0.2755\n",
      "Epoch: 2000, Loss: 0.2733\n",
      "Epoch: 2100, Loss: 0.2713\n",
      "Epoch: 2200, Loss: 0.2695\n",
      "Epoch: 2300, Loss: 0.2679\n",
      "Epoch: 2400, Loss: 0.2663\n",
      "Epoch: 2500, Loss: 0.2649\n",
      "Epoch: 2600, Loss: 0.2636\n",
      "Epoch: 2700, Loss: 0.2624\n",
      "Epoch: 2800, Loss: 0.2612\n",
      "Epoch: 2900, Loss: 0.2602\n",
      "Epoch: 3000, Loss: 0.2592\n",
      "Epoch: 3100, Loss: 0.2582\n",
      "Epoch: 3200, Loss: 0.2573\n",
      "Epoch: 3300, Loss: 0.2565\n",
      "Epoch: 3400, Loss: 0.2557\n",
      "Epoch: 3500, Loss: 0.2550\n",
      "Epoch: 3600, Loss: 0.2543\n",
      "Epoch: 3700, Loss: 0.2536\n",
      "Epoch: 3800, Loss: 0.2530\n",
      "Epoch: 3900, Loss: 0.2524\n",
      "Epoch: 4000, Loss: 0.2518\n",
      "Epoch: 4100, Loss: 0.2513\n",
      "Epoch: 4200, Loss: 0.2507\n",
      "Epoch: 4300, Loss: 0.2503\n",
      "Epoch: 4400, Loss: 0.2498\n",
      "Epoch: 4500, Loss: 0.2493\n",
      "Epoch: 4600, Loss: 0.2489\n",
      "Epoch: 4700, Loss: 0.2485\n",
      "Epoch: 4800, Loss: 0.2481\n",
      "Epoch: 4900, Loss: 0.2477\n",
      "Epoch: 5000, Loss: 0.2473\n",
      "Epoch: 5100, Loss: 0.2470\n",
      "Epoch: 5200, Loss: 0.2466\n",
      "Epoch: 5300, Loss: 0.2463\n",
      "Epoch: 5400, Loss: 0.2460\n",
      "Epoch: 5500, Loss: 0.2457\n",
      "Epoch: 5600, Loss: 0.2454\n",
      "Epoch: 5700, Loss: 0.2451\n",
      "Epoch: 5800, Loss: 0.2449\n",
      "Epoch: 5900, Loss: 0.2446\n",
      "Epoch: 6000, Loss: 0.2443\n",
      "Epoch: 6100, Loss: 0.2441\n",
      "Epoch: 6200, Loss: 0.2439\n",
      "Epoch: 6300, Loss: 0.2436\n",
      "Epoch: 6400, Loss: 0.2434\n",
      "Epoch: 6500, Loss: 0.2432\n",
      "Epoch: 6600, Loss: 0.2430\n",
      "Epoch: 6700, Loss: 0.2428\n",
      "Epoch: 6800, Loss: 0.2426\n",
      "Epoch: 6900, Loss: 0.2424\n",
      "Epoch: 7000, Loss: 0.2422\n",
      "Epoch: 7100, Loss: 0.2420\n",
      "Epoch: 7200, Loss: 0.2418\n",
      "Epoch: 7300, Loss: 0.2417\n",
      "Epoch: 7400, Loss: 0.2415\n",
      "Epoch: 7500, Loss: 0.2413\n",
      "Epoch: 7600, Loss: 0.2412\n",
      "Epoch: 7700, Loss: 0.2410\n",
      "Epoch: 7800, Loss: 0.2409\n",
      "Epoch: 7900, Loss: 0.2407\n",
      "Epoch: 8000, Loss: 0.2406\n",
      "Epoch: 8100, Loss: 0.2405\n",
      "Epoch: 8200, Loss: 0.2403\n",
      "Epoch: 8300, Loss: 0.2402\n",
      "Epoch: 8400, Loss: 0.2401\n",
      "Epoch: 8500, Loss: 0.2399\n",
      "Epoch: 8600, Loss: 0.2398\n",
      "Epoch: 8700, Loss: 0.2397\n",
      "Epoch: 8800, Loss: 0.2396\n",
      "Epoch: 8900, Loss: 0.2395\n",
      "Epoch: 9000, Loss: 0.2393\n",
      "Epoch: 9100, Loss: 0.2392\n",
      "Epoch: 9200, Loss: 0.2391\n",
      "Epoch: 9300, Loss: 0.2390\n",
      "Epoch: 9400, Loss: 0.2389\n",
      "Epoch: 9500, Loss: 0.2388\n",
      "Epoch: 9600, Loss: 0.2387\n",
      "Epoch: 9700, Loss: 0.2386\n",
      "Epoch: 9800, Loss: 0.2385\n",
      "Epoch: 9900, Loss: 0.2384\n",
      "Epoch: 10000, Loss: 0.2384\n",
      "Epoch: 10100, Loss: 0.2383\n",
      "Epoch: 10200, Loss: 0.2382\n",
      "Epoch: 10300, Loss: 0.2381\n",
      "Epoch: 10400, Loss: 0.2380\n",
      "Epoch: 10500, Loss: 0.2379\n",
      "Epoch: 10600, Loss: 0.2378\n",
      "Epoch: 10700, Loss: 0.2378\n",
      "Epoch: 10800, Loss: 0.2377\n",
      "Epoch: 10900, Loss: 0.2376\n",
      "Epoch: 11000, Loss: 0.2375\n",
      "Epoch: 11100, Loss: 0.2375\n",
      "Epoch: 11200, Loss: 0.2374\n",
      "Epoch: 11300, Loss: 0.2373\n",
      "Epoch: 11400, Loss: 0.2373\n",
      "Epoch: 11500, Loss: 0.2372\n",
      "Epoch: 11600, Loss: 0.2371\n",
      "Epoch: 11700, Loss: 0.2371\n",
      "Epoch: 11800, Loss: 0.2370\n",
      "Epoch: 11900, Loss: 0.2369\n",
      "Epoch: 12000, Loss: 0.2369\n",
      "Epoch: 12100, Loss: 0.2368\n",
      "Epoch: 12200, Loss: 0.2367\n",
      "Epoch: 12300, Loss: 0.2367\n",
      "Epoch: 12400, Loss: 0.2366\n",
      "Epoch: 12500, Loss: 0.2366\n",
      "Epoch: 12600, Loss: 0.2365\n",
      "Epoch: 12700, Loss: 0.2365\n",
      "Epoch: 12800, Loss: 0.2364\n",
      "Epoch: 12900, Loss: 0.2363\n",
      "Epoch: 13000, Loss: 0.2363\n",
      "Epoch: 13100, Loss: 0.2362\n",
      "Epoch: 13200, Loss: 0.2362\n",
      "Epoch: 13300, Loss: 0.2361\n",
      "Epoch: 13400, Loss: 0.2361\n",
      "Epoch: 13500, Loss: 0.2360\n",
      "Epoch: 13600, Loss: 0.2360\n",
      "Epoch: 13700, Loss: 0.2359\n",
      "Epoch: 13800, Loss: 0.2359\n",
      "Epoch: 13900, Loss: 0.2358\n",
      "Epoch: 14000, Loss: 0.2358\n",
      "Epoch: 14100, Loss: 0.2358\n",
      "Epoch: 14200, Loss: 0.2357\n",
      "Epoch: 14300, Loss: 0.2357\n",
      "Epoch: 14400, Loss: 0.2356\n",
      "Epoch: 14500, Loss: 0.2356\n",
      "Epoch: 14600, Loss: 0.2355\n",
      "Epoch: 14700, Loss: 0.2355\n",
      "Epoch: 14800, Loss: 0.2355\n",
      "Epoch: 14900, Loss: 0.2354\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(input_size=X_train.shape[1], learning_rate=0.01, epochs=15000)\n",
    "nn.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Accuracy: 0.8892\n"
     ]
    }
   ],
   "source": [
    "y_pred_nn = nn.predict(X_test)\n",
    "nn_accuracy = accuracy_score(y_test, y_pred_nn)\n",
    "print(f\"Neural Network Accuracy: {nn_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Accuracy remains the same with both 10,000 and 15,000 epochs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
